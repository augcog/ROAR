{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec3bd95",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8019d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e535acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b43c9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a1ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vehicle_states(dir: Path, regex=\"/*.npy\") -> List[str]:\n",
    "    file_paths = sorted(glob.glob((dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    return file_paths\n",
    "\n",
    "def load_images(dir: Path, regex=\"/*.png\") -> List:\n",
    "    file_paths = sorted(glob.glob((image_dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def load_depth_images(dir, regex=\"/*.npy\") -> List:\n",
    "    file_paths = sorted(glob.glob((dir.as_posix() + regex)), key=os.path.getmtime)\n",
    "    return file_paths\n",
    "\n",
    "def load_data_paths():\n",
    "    #rgb_images = load_images(Path(\"../data/output/front_rgb/\"), regex=\"/frame_*\")\n",
    "    vehicle_states_paths = load_vehicle_states(dir=Path(\"../data/output/vehicle_state\"))\n",
    "    depth_images_paths = load_depth_images(dir=Path(\"../data/output/front_depth\"))\n",
    "    X = depth_images_paths\n",
    "    y = vehicle_states_paths\n",
    "    \n",
    "    X = np.array(X[0: min(len(X), len(y))])\n",
    "    y = np.array(y[0: min(len(X), len(y))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e066bc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4234 training and 43 testing data for a total of 4277\n"
     ]
    }
   ],
   "source": [
    "X_paths, y_paths = load_data_paths()\n",
    "test_ratio = 0.01\n",
    "length = len(X_paths)\n",
    "indices = np.random.permutation(length)\n",
    "num_train = int(length * (1-test_ratio))\n",
    "training_idx, test_idx = indices[:num_train], indices[num_train:]\n",
    "X_paths_train, X_paths_test, y_paths_train, y_paths_test = X_paths[training_idx], X_paths[test_idx], y_paths[training_idx], y_paths[test_idx]\n",
    "\n",
    "print(f\"Found {len(X_paths_train)} training and {len(X_paths_test)} testing data for a total of {len(X_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15bba9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55b0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(fpath):\n",
    "    state = np.load(fpath, allow_pickle=True)\n",
    "    return state\n",
    "def load_depth(fpath):\n",
    "    image = np.expand_dims(np.load(fpath), -1)\n",
    "    return image\n",
    "def generate_data(X_paths, y_paths, batch_size=16, shuffle=True, \n",
    "                    aug_likelihood=0.5, \n",
    "                    data_aug_pct=0.8, \n",
    "                    steering_threshold=0.2, \n",
    "                    straight_steer_drop_prob=0.5,\n",
    "                    straight_steer_cal_prob=0.6,\n",
    "                     image_width=600, image_height=800, channel=1, num_features=2):\n",
    "    assert len(X_paths) == len(y_paths), f\"Dimension mismatch: Got {len(X_paths)} X but {len(y)} y\"\n",
    "    \n",
    "    \n",
    "    batch = np.zeros((batch_size, image_width, image_height, channel), dtype=np.float32)\n",
    "    labels = np.zeros((batch_size, num_features))\n",
    "    while True:\n",
    "        k = 0\n",
    "        while k < batch_size:\n",
    "            idx = np.random.randint(0, len(X_paths))\n",
    "            X_path, y_path = X_paths[idx], y_paths[idx]\n",
    "            b = load_depth(X_path)\n",
    "            t_s = load_state(y_path)[-2:]\n",
    "            t = t_s[0]\n",
    "            s = t_s[1]\n",
    "            \n",
    "            if abs(s) < steering_threshold and np.random.sample() < straight_steer_drop_prob:\n",
    "                continue\n",
    "            \n",
    "            if abs(s) < steering_threshold and np.random.sample() < straight_steer_cal_prob:\n",
    "                s = s + (np.random.sample() - 0.5) # sample() produces rand num in [0, 1] -> want [-0.5, 0.5]\n",
    "            batch[k] = b\n",
    "            labels[k] = [t,s]\n",
    "            k += 1\n",
    "        yield batch, np.clip(labels, -1, 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6850aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generate_data(X_paths_train, y_paths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8142ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch = (16, 600, 800, 1) | Sample label = (16, 2)\n"
     ]
    }
   ],
   "source": [
    "batch, label = next(gen)\n",
    "print(f\"Sample batch = {np.shape(batch)} | Sample label = {np.shape(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da5d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(steerings: np.ndarray, title=\"Title\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    ax.grid(True)\n",
    "    ax.set(title=title)\n",
    "    count, bins, _ = ax.hist(steerings, bins=25, histtype='bar')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_images(imgs, labels, cols=5, fig_size=(15, 5)):\n",
    "    rows = len(imgs) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=fig_size)\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c]\n",
    "            img = imgs[cols * r + c] * 255\n",
    "            lb = labels[cols * r + c]\n",
    "            ax.imshow(img.astype(np.uint8))\n",
    "            ax.axis('on')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set(title=lb)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_sample_images(X, y):\n",
    "    gen = generate_images(X=X, y=y, batch_size=20)\n",
    "    b, s = next(gen)\n",
    "    show_images(b[0:20], s[0:20])\n",
    "\n",
    "\n",
    "def plot_results(hist, metrics, xlb, ylb, title, leg, fsize=(10, 5)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=fsize)\n",
    "    for m in metrics:\n",
    "        ax.plot(hist.history[m])\n",
    "\n",
    "    ax.set(xlabel=xlb, ylabel=ylb, title=title)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.legend(leg, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f0595",
   "metadata": {},
   "source": [
    "## Explore & Analyise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a9f50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = generate_data(X_paths_train, y_paths_train, batch_size=100)\n",
    "b, control = next(gen)\n",
    "plot_hist(control,\"training steering & throttle distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d874f",
   "metadata": {},
   "source": [
    "## Define model & start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae8572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import nvidia_model_throttle_steering\n",
    "m = nvidia_model_throttle_steering(input_shape=(600,800, 1))\n",
    "batch_size = 16\n",
    "train_gen = generate_data(X_paths_train, y_paths_train, batch_size)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"nvidia_model_throttle_and_steering.h5\", monitor=\"val_loss\", save_best_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='depth_nvidia_model_logs', histogram_freq=1, write_graph=True,\n",
    "        write_images=True, update_freq=1000, profile_batch=2,\n",
    "        embeddings_freq=0, embeddings_metadata=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c7621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tests = np.array([load_depth(X_path)  for X_path in X_paths_test])\n",
    "y_tests = np.array([load_state(y_path)[-2:] for y_path in y_paths_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c6a104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.1446WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.1442\n",
      "Epoch 2/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0691Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0690 - val_loss: 0.0583\n",
      "Epoch 3/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0649WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0649\n",
      "Epoch 4/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0648Epoch 1/1000\n",
      "200/200 [==============================] - 53s 266ms/step - loss: 0.0649 - val_loss: 0.1075\n",
      "Epoch 5/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 6/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 0.0610 - val_loss: 3.6473\n",
      "Epoch 7/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 8/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0617 - val_loss: 0.0484\n",
      "Epoch 9/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 10/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0615 - val_loss: 0.0484\n",
      "Epoch 11/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 12/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0594 - val_loss: 0.0474\n",
      "Epoch 13/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0626\n",
      "Epoch 14/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0604 - val_loss: 0.0520\n",
      "Epoch 15/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0619\n",
      "Epoch 16/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0584 - val_loss: 0.0437\n",
      "Epoch 17/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 18/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0621 - val_loss: 0.0489\n",
      "Epoch 19/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 20/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 59s 296ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 21/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 22/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 62s 311ms/step - loss: 0.0609 - val_loss: 0.0463\n",
      "Epoch 23/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 24/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 0.0612 - val_loss: 0.0506\n",
      "Epoch 25/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 26/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 67s 337ms/step - loss: 0.0598 - val_loss: 0.0504\n",
      "Epoch 27/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0582\n",
      "Epoch 28/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 69s 346ms/step - loss: 0.0594 - val_loss: 0.0463\n",
      "Epoch 29/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 30/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 0.0616 - val_loss: 0.0471\n",
      "Epoch 31/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 32/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 67s 337ms/step - loss: 0.0589 - val_loss: 0.0498\n",
      "Epoch 33/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 34/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 73s 363ms/step - loss: 0.0601 - val_loss: 0.0463\n",
      "Epoch 35/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 36/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 74s 369ms/step - loss: 0.0615 - val_loss: 0.0466\n",
      "Epoch 37/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 38/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.0614 - val_loss: 0.0472\n",
      "Epoch 39/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 40/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 74s 368ms/step - loss: 0.0600 - val_loss: 0.0470\n",
      "Epoch 41/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 42/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 72s 360ms/step - loss: 0.0603 - val_loss: 0.0495\n",
      "Epoch 43/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 44/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 75s 376ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 45/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 46/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 74s 372ms/step - loss: 0.0594 - val_loss: 6.8833\n",
      "Epoch 47/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 48/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 73s 366ms/step - loss: 0.0601 - val_loss: 0.0473\n",
      "Epoch 49/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 50/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 73s 364ms/step - loss: 0.0604 - val_loss: 0.0468\n",
      "Epoch 51/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 52/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 73s 363ms/step - loss: 0.0601 - val_loss: 0.0499\n",
      "Epoch 53/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 54/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 72s 358ms/step - loss: 0.0611 - val_loss: 0.0483\n",
      "Epoch 55/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 56/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 71s 356ms/step - loss: 0.0597 - val_loss: 0.0464\n",
      "Epoch 57/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 58/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 72s 358ms/step - loss: 0.0611 - val_loss: 0.0472\n",
      "Epoch 59/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 60/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 71s 356ms/step - loss: 0.0606 - val_loss: 0.0461\n",
      "Epoch 61/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 62/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 72s 359ms/step - loss: 0.0618 - val_loss: 0.0507\n",
      "Epoch 63/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 64/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 73s 364ms/step - loss: 0.0596 - val_loss: 0.0472\n",
      "Epoch 65/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 66/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 74s 372ms/step - loss: 0.0594 - val_loss: 0.0471\n",
      "Epoch 67/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 68/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.0594 - val_loss: 0.0470\n",
      "Epoch 69/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0633WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0632\n",
      "Epoch 70/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 75s 376ms/step - loss: 0.0603 - val_loss: 0.0462\n",
      "Epoch 71/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 72/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 74s 371ms/step - loss: 0.0619 - val_loss: 0.0454\n",
      "Epoch 73/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 74/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 77s 385ms/step - loss: 0.0604 - val_loss: 0.0485\n",
      "Epoch 75/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 76/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.0615 - val_loss: 0.0469\n",
      "Epoch 77/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 78/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.0592 - val_loss: 0.0463\n",
      "Epoch 79/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 80s 401ms/step - loss: 0.0586 - val_loss: 0.0471\n",
      "Epoch 81/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 82/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 78s 392ms/step - loss: 0.0594 - val_loss: 0.0484\n",
      "Epoch 83/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 84/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 78s 388ms/step - loss: 0.0606 - val_loss: 26.3670\n",
      "Epoch 85/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0580\n",
      "Epoch 86/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 74s 371ms/step - loss: 0.0611 - val_loss: 0.1537\n",
      "Epoch 87/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0620\n",
      "Epoch 88/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.0594 - val_loss: 0.0462\n",
      "Epoch 89/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0603\n",
      "Epoch 90/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 59s 295ms/step - loss: 0.0602 - val_loss: 0.0468\n",
      "Epoch 91/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 92/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 59s 297ms/step - loss: 0.0599 - val_loss: 0.0472\n",
      "Epoch 93/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 94/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0592 - val_loss: 0.0479\n",
      "Epoch 95/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 96/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0601 - val_loss: 0.0485\n",
      "Epoch 97/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 98/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0612 - val_loss: 0.0454\n",
      "Epoch 99/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 100/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0594 - val_loss: 0.0450\n",
      "Epoch 101/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 102/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0601 - val_loss: 0.0479\n",
      "Epoch 103/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 104/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0591 - val_loss: 0.0478\n",
      "Epoch 105/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 106/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0592 - val_loss: 0.0498\n",
      "Epoch 107/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 108/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0611 - val_loss: 0.0475\n",
      "Epoch 109/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 110/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0597 - val_loss: 0.0486\n",
      "Epoch 111/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 112/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0615 - val_loss: 0.0468\n",
      "Epoch 113/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 114/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0602 - val_loss: 0.0472\n",
      "Epoch 115/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 116/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0614 - val_loss: 0.0468\n",
      "Epoch 117/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 118/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0591 - val_loss: 0.0470\n",
      "Epoch 119/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 120/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0577Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0577 - val_loss: 0.0453\n",
      "Epoch 121/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 122/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0610 - val_loss: 0.0463\n",
      "Epoch 123/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 124/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0601 - val_loss: 0.0465\n",
      "Epoch 125/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0621WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0621\n",
      "Epoch 126/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 0.0589 - val_loss: 0.0462\n",
      "Epoch 127/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 128/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0614 - val_loss: 0.0479\n",
      "Epoch 129/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 130/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0594 - val_loss: 0.0460\n",
      "Epoch 131/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 132/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0606 - val_loss: 0.0477\n",
      "Epoch 133/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 134/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0595 - val_loss: 0.0477\n",
      "Epoch 135/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 136/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0611 - val_loss: 0.0480\n",
      "Epoch 137/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 138/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0603 - val_loss: 0.0469\n",
      "Epoch 139/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 140/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0610 - val_loss: 0.0475\n",
      "Epoch 141/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 142/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0596 - val_loss: 0.0530\n",
      "Epoch 143/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 144/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0607 - val_loss: 0.0471\n",
      "Epoch 145/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 146/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 147/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 148/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0594 - val_loss: 0.0470\n",
      "Epoch 149/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 150/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0613 - val_loss: 0.0466\n",
      "Epoch 151/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 152/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0603 - val_loss: 0.0466\n",
      "Epoch 153/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 154/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 59s 295ms/step - loss: 0.0598 - val_loss: 1.2800\n",
      "Epoch 155/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 156/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0601 - val_loss: 0.0466\n",
      "Epoch 157/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 158/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0600 - val_loss: 0.0459\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0589\n",
      "Epoch 160/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0604 - val_loss: 0.0490\n",
      "Epoch 161/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 162/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0602 - val_loss: 0.0439\n",
      "Epoch 163/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 164/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0606 - val_loss: 0.0483\n",
      "Epoch 165/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 166/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0593 - val_loss: 0.0496\n",
      "Epoch 167/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 168/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0601 - val_loss: 0.0479\n",
      "Epoch 169/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 170/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0601 - val_loss: 0.0459\n",
      "Epoch 171/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 172/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0597 - val_loss: 0.0484\n",
      "Epoch 173/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 174/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0603 - val_loss: 0.0465\n",
      "Epoch 175/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 176/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0601 - val_loss: 8.3349\n",
      "Epoch 177/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 178/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0597 - val_loss: 0.0450\n",
      "Epoch 179/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 180/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0615 - val_loss: 0.0480\n",
      "Epoch 181/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 182/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0618 - val_loss: 0.0472\n",
      "Epoch 183/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 184/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0598 - val_loss: 0.0475\n",
      "Epoch 185/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 186/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0592 - val_loss: 0.0463\n",
      "Epoch 187/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 188/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0596 - val_loss: 0.0477\n",
      "Epoch 189/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 190/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0598 - val_loss: 0.1396\n",
      "Epoch 191/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 192/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0600 - val_loss: 16.2714\n",
      "Epoch 193/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 194/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0590 - val_loss: 0.0497\n",
      "Epoch 195/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 196/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0599 - val_loss: 63.6357\n",
      "Epoch 197/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 198/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0608 - val_loss: 0.0481\n",
      "Epoch 199/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 200/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0601 - val_loss: 0.0472\n",
      "Epoch 201/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 202/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0591 - val_loss: 0.0465\n",
      "Epoch 203/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 204/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0606 - val_loss: 0.0478\n",
      "Epoch 205/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 206/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0613 - val_loss: 0.2192\n",
      "Epoch 207/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 208/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0602 - val_loss: 0.0486\n",
      "Epoch 209/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 210/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0590 - val_loss: 0.0475\n",
      "Epoch 211/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0625\n",
      "Epoch 212/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0619 - val_loss: 0.0477\n",
      "Epoch 213/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 214/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0625Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0625 - val_loss: 0.0474\n",
      "Epoch 215/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 216/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0598 - val_loss: 0.2141\n",
      "Epoch 217/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 218/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0605 - val_loss: 0.0487\n",
      "Epoch 219/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 220/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0598 - val_loss: 0.0462\n",
      "Epoch 221/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0576\n",
      "Epoch 222/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0598 - val_loss: 0.0461\n",
      "Epoch 223/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0620\n",
      "Epoch 224/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0600 - val_loss: 0.0451\n",
      "Epoch 225/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 226/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0608 - val_loss: 0.3357\n",
      "Epoch 227/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 228/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0598 - val_loss: 0.0456\n",
      "Epoch 229/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 230/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0598 - val_loss: 0.0473\n",
      "Epoch 231/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 232/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0603 - val_loss: 0.0472\n",
      "Epoch 233/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 234/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0605 - val_loss: 0.0480\n",
      "Epoch 235/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 236/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0605 - val_loss: 0.0470\n",
      "Epoch 237/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 238/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0611 - val_loss: 0.0484\n",
      "Epoch 239/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 240/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0591 - val_loss: 0.0483\n",
      "Epoch 241/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 242/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0614 - val_loss: 0.0688\n",
      "Epoch 243/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 244/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.0602 - val_loss: 0.0471\n",
      "Epoch 245/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 246/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0609 - val_loss: 63.2319\n",
      "Epoch 247/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 248/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0613 - val_loss: 0.0467\n",
      "Epoch 249/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 250/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0604 - val_loss: 0.0487\n",
      "Epoch 251/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 252/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0587 - val_loss: 0.0479\n",
      "Epoch 253/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 254/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0591 - val_loss: 0.0470\n",
      "Epoch 255/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 256/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0595 - val_loss: 0.0464\n",
      "Epoch 257/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 258/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0587 - val_loss: 0.0452\n",
      "Epoch 259/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 260/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0595 - val_loss: 0.0480\n",
      "Epoch 261/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 262/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0598 - val_loss: 14.8771\n",
      "Epoch 263/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 264/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 0.0596 - val_loss: 0.0468\n",
      "Epoch 265/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 266/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0465\n",
      "Epoch 267/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 268/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0588 - val_loss: 0.0487\n",
      "Epoch 269/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 270/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0603 - val_loss: 0.0464\n",
      "Epoch 271/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 272/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0603 - val_loss: 0.0485\n",
      "Epoch 273/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0573WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0574\n",
      "Epoch 274/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0597 - val_loss: 0.0479\n",
      "Epoch 275/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 276/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0611 - val_loss: 0.0471\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 278/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0593 - val_loss: 0.0447\n",
      "Epoch 279/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 280/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0617 - val_loss: 0.4329\n",
      "Epoch 281/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 282/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0609 - val_loss: 0.0480\n",
      "Epoch 283/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 284/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0606 - val_loss: 0.0468\n",
      "Epoch 285/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 286/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0604 - val_loss: 0.0468\n",
      "Epoch 287/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0618\n",
      "Epoch 288/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0609 - val_loss: 0.0482\n",
      "Epoch 289/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 290/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0611 - val_loss: 0.0472\n",
      "Epoch 291/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0577\n",
      "Epoch 292/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0468\n",
      "Epoch 293/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 294/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0604 - val_loss: 0.0478\n",
      "Epoch 295/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 296/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0611 - val_loss: 0.0473\n",
      "Epoch 297/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 298/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0603 - val_loss: 0.0473\n",
      "Epoch 299/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 300/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0609 - val_loss: 0.0464\n",
      "Epoch 301/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 302/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0589 - val_loss: 2.6696\n",
      "Epoch 303/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 304/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0607 - val_loss: 0.0476\n",
      "Epoch 305/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 306/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0592 - val_loss: 0.0471\n",
      "Epoch 307/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 308/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0576\n",
      "Epoch 309/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 310/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0601 - val_loss: 0.0478\n",
      "Epoch 311/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 312/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0612 - val_loss: 0.0455\n",
      "Epoch 313/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 314/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0601 - val_loss: 0.0469\n",
      "Epoch 315/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0604 - val_loss: 0.0466\n",
      "Epoch 317/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 318/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0607 - val_loss: 0.0475\n",
      "Epoch 319/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 320/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0586 - val_loss: 0.0474\n",
      "Epoch 321/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 322/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0611 - val_loss: 0.0465\n",
      "Epoch 323/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 324/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0610 - val_loss: 0.0530\n",
      "Epoch 325/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 326/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0614 - val_loss: 0.0475\n",
      "Epoch 327/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 328/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0591 - val_loss: 0.0458\n",
      "Epoch 329/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 330/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0595 - val_loss: 0.0489\n",
      "Epoch 331/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 332/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0607 - val_loss: 0.0481\n",
      "Epoch 333/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 334/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0465\n",
      "Epoch 335/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 336/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0612 - val_loss: 0.0465\n",
      "Epoch 337/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 338/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0606 - val_loss: 0.0475\n",
      "Epoch 339/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 340/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0611 - val_loss: 0.0474\n",
      "Epoch 341/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 342/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0606 - val_loss: 0.0469\n",
      "Epoch 343/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 344/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0602 - val_loss: 0.0461\n",
      "Epoch 345/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 346/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0581 - val_loss: 0.0802\n",
      "Epoch 347/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 348/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0617 - val_loss: 0.0479\n",
      "Epoch 349/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 350/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0612 - val_loss: 0.0474\n",
      "Epoch 351/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 352/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0596 - val_loss: 0.0465\n",
      "Epoch 353/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 354/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0596 - val_loss: 0.0459\n",
      "Epoch 355/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 356/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0590 - val_loss: 0.0473\n",
      "Epoch 357/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0595\n",
      "Epoch 358/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0599 - val_loss: 0.0490\n",
      "Epoch 359/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0579\n",
      "Epoch 360/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0608 - val_loss: 0.0478\n",
      "Epoch 361/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 362/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0607 - val_loss: 0.0477\n",
      "Epoch 363/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 364/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0592 - val_loss: 0.0465\n",
      "Epoch 365/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 366/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0592 - val_loss: 0.0469\n",
      "Epoch 367/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 368/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0596 - val_loss: 0.0475\n",
      "Epoch 369/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 370/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0590 - val_loss: 0.0444\n",
      "Epoch 371/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 372/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0467\n",
      "Epoch 373/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 374/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0467\n",
      "Epoch 375/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 376/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0592 - val_loss: 0.0473\n",
      "Epoch 377/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 378/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0472\n",
      "Epoch 379/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 380/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0596 - val_loss: 0.0475\n",
      "Epoch 381/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 382/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0596 - val_loss: 0.0466\n",
      "Epoch 383/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 384/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 385/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 386/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0618 - val_loss: 0.0494\n",
      "Epoch 387/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 388/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0608 - val_loss: 0.8280\n",
      "Epoch 389/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 390/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0602 - val_loss: 0.0483\n",
      "Epoch 391/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 392/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0474\n",
      "Epoch 393/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 394/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0604 - val_loss: 13.2869\n",
      "Epoch 395/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 396/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 397/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 398/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0597 - val_loss: 0.0469\n",
      "Epoch 399/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 400/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0611 - val_loss: 0.0484\n",
      "Epoch 401/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 402/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0599 - val_loss: 0.0482\n",
      "Epoch 403/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 404/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0583 - val_loss: 0.0462\n",
      "Epoch 405/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 406/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0587 - val_loss: 0.0457\n",
      "Epoch 407/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 408/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0609 - val_loss: 0.0470\n",
      "Epoch 409/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 410/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0610 - val_loss: 0.0474\n",
      "Epoch 411/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 412/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0616 - val_loss: 0.0469\n",
      "Epoch 413/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 414/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0486\n",
      "Epoch 415/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 416/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0588 - val_loss: 0.0457\n",
      "Epoch 417/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0581\n",
      "Epoch 418/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0625Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0625 - val_loss: 0.0463\n",
      "Epoch 419/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 420/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0603 - val_loss: 0.0474\n",
      "Epoch 421/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 422/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0599 - val_loss: 0.0477\n",
      "Epoch 423/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 424/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0595 - val_loss: 0.0477\n",
      "Epoch 425/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 426/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0597 - val_loss: 0.0470\n",
      "Epoch 427/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 428/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0597 - val_loss: 0.0472\n",
      "Epoch 429/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 430/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0586 - val_loss: 0.0461\n",
      "Epoch 431/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 432/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 433/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 434/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0587 - val_loss: 0.0467\n",
      "Epoch 435/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 436/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0609 - val_loss: 0.0471\n",
      "Epoch 437/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 438/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0603 - val_loss: 0.0473\n",
      "Epoch 439/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0619\n",
      "Epoch 440/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0596 - val_loss: 0.0470\n",
      "Epoch 441/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 442/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0593 - val_loss: 87063.3177\n",
      "Epoch 443/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 444/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0596 - val_loss: 0.0472\n",
      "Epoch 445/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 446/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0590 - val_loss: 0.0468\n",
      "Epoch 447/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 448/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0610 - val_loss: 0.0479\n",
      "Epoch 449/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 450/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0610 - val_loss: 0.0461\n",
      "Epoch 451/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 452/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0608 - val_loss: 0.0473\n",
      "Epoch 453/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 454/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0596 - val_loss: 0.0468\n",
      "Epoch 455/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 456/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 457/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 458/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0593 - val_loss: 0.0466\n",
      "Epoch 459/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 460/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0614 - val_loss: 0.0473\n",
      "Epoch 461/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 462/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0605 - val_loss: 0.0467\n",
      "Epoch 463/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 464/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0596 - val_loss: 0.0472\n",
      "Epoch 465/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 466/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0601 - val_loss: 0.0470\n",
      "Epoch 467/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0622\n",
      "Epoch 468/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0602 - val_loss: 0.0467\n",
      "Epoch 469/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 470/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0598 - val_loss: 0.0470\n",
      "Epoch 471/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 472/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0605 - val_loss: 0.0472\n",
      "Epoch 473/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 474/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0585 - val_loss: 0.0459\n",
      "Epoch 475/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 476/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0590 - val_loss: 0.0467\n",
      "Epoch 477/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 478/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0604 - val_loss: 0.0477\n",
      "Epoch 479/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 480/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0608 - val_loss: 0.0467\n",
      "Epoch 481/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 482/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0615Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0615 - val_loss: 0.0480\n",
      "Epoch 483/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 484/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0605 - val_loss: 0.0470\n",
      "Epoch 485/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 486/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0602 - val_loss: 0.0463\n",
      "Epoch 487/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 488/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0599 - val_loss: 0.0480\n",
      "Epoch 489/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 490/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0620 - val_loss: 35439.0091\n",
      "Epoch 491/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0623\n",
      "Epoch 492/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0595 - val_loss: 0.0471\n",
      "Epoch 493/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 494/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0603 - val_loss: 0.1040\n",
      "Epoch 495/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 496/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0587 - val_loss: 56.2779\n",
      "Epoch 497/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0586\n",
      "Epoch 498/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0615 - val_loss: 28.6873\n",
      "Epoch 499/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 500/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0597 - val_loss: 0.0476\n",
      "Epoch 501/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 502/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0598 - val_loss: 0.0469\n",
      "Epoch 503/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 504/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0588 - val_loss: 13.0421\n",
      "Epoch 505/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 506/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0605 - val_loss: 0.0468\n",
      "Epoch 507/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 508/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0619 - val_loss: 0.0476\n",
      "Epoch 509/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 510/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0587 - val_loss: 0.0473\n",
      "Epoch 511/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 512/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0614 - val_loss: 0.1621\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 514/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0585 - val_loss: 1.2217\n",
      "Epoch 515/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 516/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0603 - val_loss: 0.0475\n",
      "Epoch 517/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 518/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0595 - val_loss: 0.2620\n",
      "Epoch 519/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 520/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0600 - val_loss: 0.0475\n",
      "Epoch 521/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 522/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0610 - val_loss: 968.5754\n",
      "Epoch 523/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 524/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0595 - val_loss: 28.0288\n",
      "Epoch 525/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.0597\n",
      "Epoch 526/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0597 - val_loss: 0.0475\n",
      "Epoch 527/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 528/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0611 - val_loss: 0.0475\n",
      "Epoch 529/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 530/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0617 - val_loss: 0.0467\n",
      "Epoch 531/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 532/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0596 - val_loss: 0.0476\n",
      "Epoch 533/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 534/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0599 - val_loss: 0.0468\n",
      "Epoch 535/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0619\n",
      "Epoch 536/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0594 - val_loss: 0.0475\n",
      "Epoch 537/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 538/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0586 - val_loss: 0.0464\n",
      "Epoch 539/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0580WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0579\n",
      "Epoch 540/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0585 - val_loss: 0.0461\n",
      "Epoch 541/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0614\n",
      "Epoch 542/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0608 - val_loss: 0.0466\n",
      "Epoch 543/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 544/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0589 - val_loss: 0.0468\n",
      "Epoch 545/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 546/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 547/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 548/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0596 - val_loss: 0.0495\n",
      "Epoch 549/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 550/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0605 - val_loss: 0.0477\n",
      "Epoch 551/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0606 - val_loss: 0.0470\n",
      "Epoch 553/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 554/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0593 - val_loss: 0.0464\n",
      "Epoch 555/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 556/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0597 - val_loss: 0.0469\n",
      "Epoch 557/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0603\n",
      "Epoch 558/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 559/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 560/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 561/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 562/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0598 - val_loss: 0.0471\n",
      "Epoch 563/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 564/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0606 - val_loss: 0.0477\n",
      "Epoch 565/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 566/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0609 - val_loss: 0.0470\n",
      "Epoch 567/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 568/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0594 - val_loss: 0.0476\n",
      "Epoch 569/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 570/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0593 - val_loss: 0.0468\n",
      "Epoch 571/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0579WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0578\n",
      "Epoch 572/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0593 - val_loss: 0.0471\n",
      "Epoch 573/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 574/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0599 - val_loss: 0.6243\n",
      "Epoch 575/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 576/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0598 - val_loss: 0.0476\n",
      "Epoch 577/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 578/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0598 - val_loss: 0.0477\n",
      "Epoch 579/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 580/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0598 - val_loss: 0.0476\n",
      "Epoch 581/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 582/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0603 - val_loss: 0.0470\n",
      "Epoch 583/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 584/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0606 - val_loss: 0.0473\n",
      "Epoch 585/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 586/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0587 - val_loss: 0.0474\n",
      "Epoch 587/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 588/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0590 - val_loss: 0.0470\n",
      "Epoch 589/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 590/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0597 - val_loss: 0.0493\n",
      "Epoch 591/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 592/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0607 - val_loss: 0.0473\n",
      "Epoch 593/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 594/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0619 - val_loss: 0.0484\n",
      "Epoch 595/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 596/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.0593 - val_loss: 0.0466\n",
      "Epoch 597/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 598/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 599/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 600/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0599 - val_loss: 0.0466\n",
      "Epoch 601/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 602/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0602 - val_loss: 0.0470\n",
      "Epoch 603/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 604/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0592 - val_loss: 0.0463\n",
      "Epoch 605/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 606/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0607 - val_loss: 0.0469\n",
      "Epoch 607/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 608/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0582 - val_loss: 469.2914\n",
      "Epoch 609/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 610/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0602 - val_loss: 457.0368\n",
      "Epoch 611/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 612/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0607 - val_loss: 0.0482\n",
      "Epoch 613/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 614/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0592 - val_loss: 0.0502\n",
      "Epoch 615/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 616/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0613 - val_loss: 0.0487\n",
      "Epoch 617/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 618/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0599 - val_loss: 0.0486\n",
      "Epoch 619/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 620/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0611 - val_loss: 0.0453\n",
      "Epoch 621/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 622/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0610 - val_loss: 0.0467\n",
      "Epoch 623/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 624/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0600 - val_loss: 0.0490\n",
      "Epoch 625/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 626/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0611 - val_loss: 0.0463\n",
      "Epoch 627/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 628/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 54s 268ms/step - loss: 0.0617 - val_loss: 0.0478\n",
      "Epoch 629/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0616\n",
      "Epoch 630/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0590 - val_loss: 0.0458\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0596\n",
      "Epoch 632/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0612 - val_loss: 0.8746\n",
      "Epoch 633/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 634/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0604 - val_loss: 0.0470\n",
      "Epoch 635/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 636/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0595 - val_loss: 0.0464\n",
      "Epoch 637/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 638/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0616 - val_loss: 0.0479\n",
      "Epoch 639/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 640/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0600 - val_loss: 0.0467\n",
      "Epoch 641/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0569WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0569\n",
      "Epoch 642/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0605 - val_loss: 0.0465\n",
      "Epoch 643/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0580\n",
      "Epoch 644/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0605 - val_loss: 216.8349\n",
      "Epoch 645/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 646/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0604 - val_loss: 0.0462\n",
      "Epoch 647/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 648/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0593 - val_loss: 0.0458\n",
      "Epoch 649/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 650/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0589 - val_loss: 0.0464\n",
      "Epoch 651/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 652/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0615 - val_loss: 0.0473\n",
      "Epoch 653/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 654/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0593 - val_loss: 0.0477\n",
      "Epoch 655/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 656/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0605 - val_loss: 0.0477\n",
      "Epoch 657/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0577\n",
      "Epoch 658/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0611 - val_loss: 0.0477\n",
      "Epoch 659/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 660/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0589 - val_loss: 0.0469\n",
      "Epoch 661/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 662/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0604 - val_loss: 0.0474\n",
      "Epoch 663/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 664/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0596 - val_loss: 0.0469\n",
      "Epoch 665/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 666/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0609 - val_loss: 9.2986\n",
      "Epoch 667/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 668/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0622Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0624 - val_loss: 0.0472\n",
      "Epoch 669/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0623\n",
      "Epoch 670/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0605 - val_loss: 0.0458\n",
      "Epoch 671/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 672/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0611 - val_loss: 0.0463\n",
      "Epoch 673/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 674/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0594 - val_loss: 0.0480\n",
      "Epoch 675/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 676/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0601 - val_loss: 0.0458\n",
      "Epoch 677/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 678/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0595 - val_loss: 113.5214\n",
      "Epoch 679/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 680/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0594 - val_loss: 0.0500\n",
      "Epoch 681/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 682/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0591 - val_loss: 997.0543\n",
      "Epoch 683/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 684/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0595 - val_loss: 0.0469\n",
      "Epoch 685/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 686/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0600 - val_loss: 0.0472\n",
      "Epoch 687/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0576WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0577\n",
      "Epoch 688/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0598 - val_loss: 0.0478\n",
      "Epoch 689/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 690/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0596 - val_loss: 9.0266\n",
      "Epoch 691/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 692/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0591 - val_loss: 135522.8281\n",
      "Epoch 693/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 694/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0596 - val_loss: 0.0459\n",
      "Epoch 695/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 696/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0606 - val_loss: 15.5055\n",
      "Epoch 697/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 698/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0602 - val_loss: 0.0581\n",
      "Epoch 699/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 700/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0598 - val_loss: 320.8177\n",
      "Epoch 701/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 702/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0607 - val_loss: 0.0471\n",
      "Epoch 703/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 704/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0590 - val_loss: 0.0475\n",
      "Epoch 705/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 706/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0588 - val_loss: 0.0477\n",
      "Epoch 707/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 708/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0591 - val_loss: 0.0469\n",
      "Epoch 709/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 710/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0598 - val_loss: 0.0477\n",
      "Epoch 711/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 712/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 54s 269ms/step - loss: 0.0603 - val_loss: 0.0470\n",
      "Epoch 713/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 714/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0600 - val_loss: 15.4116\n",
      "Epoch 715/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 716/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0608 - val_loss: 0.0464\n",
      "Epoch 717/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0591\n",
      "Epoch 718/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0601 - val_loss: 149.0296\n",
      "Epoch 719/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 720/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0597 - val_loss: 0.0457\n",
      "Epoch 721/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 722/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0596 - val_loss: 0.0475\n",
      "Epoch 723/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 724/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0620 - val_loss: 0.0470\n",
      "Epoch 725/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0616WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 726/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 54s 270ms/step - loss: 0.0599 - val_loss: 0.0474\n",
      "Epoch 727/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 728/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0598 - val_loss: 0.0499\n",
      "Epoch 729/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.0590\n",
      "Epoch 730/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0613 - val_loss: 85.4382\n",
      "Epoch 731/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 732/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0606 - val_loss: 0.0511\n",
      "Epoch 733/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 734/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0611 - val_loss: 0.0472\n",
      "Epoch 735/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 736/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0590 - val_loss: 0.0467\n",
      "Epoch 737/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 738/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0608 - val_loss: 0.0479\n",
      "Epoch 739/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 740/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0593 - val_loss: 0.0473\n",
      "Epoch 741/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 742/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0587 - val_loss: 0.0465\n",
      "Epoch 743/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0615\n",
      "Epoch 744/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0605 - val_loss: 0.0477\n",
      "Epoch 745/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 746/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0600 - val_loss: 0.0462\n",
      "Epoch 747/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 748/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0595 - val_loss: 0.0486\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 750/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0587 - val_loss: 0.0472\n",
      "Epoch 751/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 752/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0600 - val_loss: 0.0468\n",
      "Epoch 753/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 754/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0606 - val_loss: 0.0483\n",
      "Epoch 755/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 756/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0586 - val_loss: 0.0471\n",
      "Epoch 757/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 758/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0613 - val_loss: 0.1000\n",
      "Epoch 759/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 760/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0606 - val_loss: 0.0475\n",
      "Epoch 761/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 762/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0604 - val_loss: 0.0472\n",
      "Epoch 763/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 764/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0592 - val_loss: 2.4425\n",
      "Epoch 765/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 766/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0598 - val_loss: 0.0449\n",
      "Epoch 767/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 768/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0597 - val_loss: 0.1094\n",
      "Epoch 769/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0620\n",
      "Epoch 770/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0598 - val_loss: 0.0485\n",
      "Epoch 771/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0586\n",
      "Epoch 772/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0604 - val_loss: 0.0471\n",
      "Epoch 773/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 774/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0617 - val_loss: 0.0448\n",
      "Epoch 775/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 776/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0604 - val_loss: 0.0472\n",
      "Epoch 777/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 778/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0606 - val_loss: 0.0477\n",
      "Epoch 779/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0587\n",
      "Epoch 780/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0599 - val_loss: 0.0472\n",
      "Epoch 781/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 782/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0597 - val_loss: 0.0478\n",
      "Epoch 783/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 784/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0613 - val_loss: 0.0491\n",
      "Epoch 785/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 786/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0613 - val_loss: 0.0475\n",
      "Epoch 787/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 788/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0605 - val_loss: 0.0467\n",
      "Epoch 789/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 790/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 0.0608 - val_loss: 0.0466\n",
      "Epoch 791/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 792/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 0.0589 - val_loss: 0.0463\n",
      "Epoch 793/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 794/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0605 - val_loss: 0.0486\n",
      "Epoch 795/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 796/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 0.0602 - val_loss: 0.0468\n",
      "Epoch 797/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 798/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0601 - val_loss: 5.1414\n",
      "Epoch 799/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 800/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0592 - val_loss: 0.0453\n",
      "Epoch 801/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 802/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0583Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0584 - val_loss: 0.0469\n",
      "Epoch 803/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 804/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0599 - val_loss: 0.0470\n",
      "Epoch 805/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 806/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0602 - val_loss: 0.0474\n",
      "Epoch 807/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 808/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0605 - val_loss: 0.0468\n",
      "Epoch 809/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 810/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0583Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0583 - val_loss: 0.0464\n",
      "Epoch 811/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 812/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0582Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0583 - val_loss: 0.0466\n",
      "Epoch 813/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 814/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 815/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 816/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0606 - val_loss: 0.0468\n",
      "Epoch 817/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 818/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0604 - val_loss: 0.0473\n",
      "Epoch 819/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 820/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0611 - val_loss: 0.0475\n",
      "Epoch 821/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 822/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0607 - val_loss: 4.2070\n",
      "Epoch 823/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0578WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0579\n",
      "Epoch 824/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0570Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0571 - val_loss: 0.0464\n",
      "Epoch 825/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0583WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0582\n",
      "Epoch 826/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0614 - val_loss: 0.0484\n",
      "Epoch 827/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 828/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0594 - val_loss: 0.0467\n",
      "Epoch 829/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 830/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0588 - val_loss: 0.0467\n",
      "Epoch 831/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 832/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0609 - val_loss: 0.0477\n",
      "Epoch 833/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0606\n",
      "Epoch 834/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0596 - val_loss: 0.0870\n",
      "Epoch 835/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 836/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0605 - val_loss: 0.0474\n",
      "Epoch 837/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 838/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0607 - val_loss: 0.0468\n",
      "Epoch 839/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 840/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0607 - val_loss: 0.0466\n",
      "Epoch 841/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 842/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 0.0595 - val_loss: 0.0466\n",
      "Epoch 843/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 844/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0613 - val_loss: 14.1805\n",
      "Epoch 845/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 846/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0592 - val_loss: 0.0469\n",
      "Epoch 847/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 848/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0591 - val_loss: 0.5545\n",
      "Epoch 849/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 850/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0595 - val_loss: 0.1776\n",
      "Epoch 851/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 852/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 0.0602 - val_loss: 0.3370\n",
      "Epoch 853/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 854/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0594 - val_loss: 0.0947\n",
      "Epoch 855/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 856/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0585 - val_loss: 0.0483\n",
      "Epoch 857/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 858/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 55s 277ms/step - loss: 0.0587 - val_loss: 0.8507\n",
      "Epoch 859/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0588\n",
      "Epoch 860/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 55s 276ms/step - loss: 0.0588 - val_loss: 0.3673\n",
      "Epoch 861/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0593\n",
      "Epoch 862/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0624Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0624 - val_loss: 0.0472\n",
      "Epoch 863/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 864/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0602 - val_loss: 0.1410\n",
      "Epoch 865/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 866/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0603 - val_loss: 0.3823\n",
      "Epoch 867/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 868/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 56s 280ms/step - loss: 0.0604 - val_loss: 1.5212\n",
      "Epoch 869/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 870/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610Epoch 1/1000\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 0.0609 - val_loss: 5.8363\n",
      "Epoch 871/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 872/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0613 - val_loss: 0.2228\n",
      "Epoch 873/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 874/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.0606 - val_loss: 0.1679\n",
      "Epoch 875/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 876/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 0.0612 - val_loss: 0.1452\n",
      "Epoch 877/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 878/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0601 - val_loss: 0.0475\n",
      "Epoch 879/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 880/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0619 - val_loss: 0.0481\n",
      "Epoch 881/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 882/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594Epoch 1/1000\n",
      "200/200 [==============================] - 57s 283ms/step - loss: 0.0595 - val_loss: 1.4919\n",
      "Epoch 883/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0613\n",
      "Epoch 884/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 56s 282ms/step - loss: 0.0588 - val_loss: 0.0568\n",
      "Epoch 885/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 886/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0603 - val_loss: 0.0742\n",
      "Epoch 887/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 888/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0586 - val_loss: 0.0501\n",
      "Epoch 889/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0576\n",
      "Epoch 890/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0589 - val_loss: 1.1562\n",
      "Epoch 891/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0609\n",
      "Epoch 892/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0589 - val_loss: 0.0467\n",
      "Epoch 893/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 894/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0599 - val_loss: 0.0469\n",
      "Epoch 895/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0581\n",
      "Epoch 896/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0581Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0582 - val_loss: 0.0465\n",
      "Epoch 897/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0611\n",
      "Epoch 898/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0602 - val_loss: 0.0833\n",
      "Epoch 899/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0612\n",
      "Epoch 900/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0593 - val_loss: 0.0478\n",
      "Epoch 901/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0617\n",
      "Epoch 902/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0604 - val_loss: 0.0467\n",
      "Epoch 903/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0607\n",
      "Epoch 904/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 57s 285ms/step - loss: 0.0596 - val_loss: 0.0469\n",
      "Epoch 905/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 906/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0592 - val_loss: 0.0518\n",
      "Epoch 907/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 908/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 57s 287ms/step - loss: 0.0600 - val_loss: 0.0667\n",
      "Epoch 909/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 910/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584Epoch 1/1000\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.0584 - val_loss: 0.0536\n",
      "Epoch 911/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618\n",
      "Epoch 912/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595Epoch 1/1000\n",
      "200/200 [==============================] - 57s 286ms/step - loss: 0.0596 - val_loss: 0.0479\n",
      "Epoch 913/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0583WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0582\n",
      "Epoch 914/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0602Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0602 - val_loss: 0.5500\n",
      "Epoch 915/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 916/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609Epoch 1/1000\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.0608 - val_loss: 0.0938\n",
      "Epoch 917/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 918/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.0598 - val_loss: 0.0467\n",
      "Epoch 919/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 920/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0578Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0578 - val_loss: 0.3130\n",
      "Epoch 921/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 922/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0606 - val_loss: 0.6831\n",
      "Epoch 923/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0604\n",
      "Epoch 924/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0591 - val_loss: 0.2140\n",
      "Epoch 925/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 926/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0586 - val_loss: 0.4943\n",
      "Epoch 927/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0586\n",
      "Epoch 928/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.0597 - val_loss: 0.9579\n",
      "Epoch 929/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0585\n",
      "Epoch 930/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 58s 288ms/step - loss: 0.0598 - val_loss: 1.7372\n",
      "Epoch 931/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 932/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0619Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0619 - val_loss: 0.1313\n",
      "Epoch 933/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 934/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0611 - val_loss: 1.1935\n",
      "Epoch 935/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 936/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598Epoch 1/1000\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.0598 - val_loss: 3.5722\n",
      "Epoch 937/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 938/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0590 - val_loss: 2.8206\n",
      "Epoch 939/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 940/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0611Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0613 - val_loss: 1.6800\n",
      "Epoch 941/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0603\n",
      "Epoch 942/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 58s 289ms/step - loss: 0.0606 - val_loss: 0.9066\n",
      "Epoch 943/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0608\n",
      "Epoch 944/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0587Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0588 - val_loss: 3.6381\n",
      "Epoch 945/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0596WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0596\n",
      "Epoch 946/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0598 - val_loss: 7.2105\n",
      "Epoch 947/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0599\n",
      "Epoch 948/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0593 - val_loss: 3.2673\n",
      "Epoch 949/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0586WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0586\n",
      "Epoch 950/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0590 - val_loss: 2.5012\n",
      "Epoch 951/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0594WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0594\n",
      "Epoch 952/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0589 - val_loss: 0.0460\n",
      "Epoch 953/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 954/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0591 - val_loss: 0.0483\n",
      "Epoch 955/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 956/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0613Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0614 - val_loss: 0.0489\n",
      "Epoch 957/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 958/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0600 - val_loss: 0.0490\n",
      "Epoch 959/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 960/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0608 - val_loss: 0.0458\n",
      "Epoch 961/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0601\n",
      "Epoch 962/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0617Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0616 - val_loss: 0.0477\n",
      "Epoch 963/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0604WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0605\n",
      "Epoch 964/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0591Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0592 - val_loss: 0.2889\n",
      "Epoch 965/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0584WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0583\n",
      "Epoch 966/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0601 - val_loss: 0.1058\n",
      "Epoch 967/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 968/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0608Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0607 - val_loss: 0.0470\n",
      "Epoch 969/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0598WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0598\n",
      "Epoch 970/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0593Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0593 - val_loss: 0.0890\n",
      "Epoch 971/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0592\n",
      "Epoch 972/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0600 - val_loss: 0.0456\n",
      "Epoch 973/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0589\n",
      "Epoch 974/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0603Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0601 - val_loss: 0.0475\n",
      "Epoch 975/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 976/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0618Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0618 - val_loss: 0.0474\n",
      "Epoch 977/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0597WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0597\n",
      "Epoch 978/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0606Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0605 - val_loss: 0.0472\n",
      "Epoch 979/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0600WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0600\n",
      "Epoch 980/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0599Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0599 - val_loss: 0.0467\n",
      "Epoch 981/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 982/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 58s 291ms/step - loss: 0.0592 - val_loss: 0.0476\n",
      "Epoch 983/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0609WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0610\n",
      "Epoch 984/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0588Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0588 - val_loss: 0.0472\n",
      "Epoch 985/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200 [============================>.] - ETA: 0s - loss: 0.0580WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0581\n",
      "Epoch 986/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0590 - val_loss: 0.0469\n",
      "Epoch 987/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0595WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0595\n",
      "Epoch 988/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0607Epoch 1/1000\n",
      "200/200 [==============================] - 59s 295ms/step - loss: 0.0607 - val_loss: 0.0455\n",
      "Epoch 989/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0601WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0602\n",
      "Epoch 990/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0603 - val_loss: 0.0478\n",
      "Epoch 991/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0585WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 992/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0620Epoch 1/1000\n",
      "200/200 [==============================] - 59s 294ms/step - loss: 0.0621 - val_loss: 0.0475\n",
      "Epoch 993/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0589WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0590\n",
      "Epoch 994/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0592 - val_loss: 0.0553\n",
      "Epoch 995/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.0591\n",
      "Epoch 996/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0612Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0612 - val_loss: 0.0471\n",
      "Epoch 997/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0572WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0571\n",
      "Epoch 998/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0592Epoch 1/1000\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0591 - val_loss: 0.0465\n",
      "Epoch 999/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0583WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0584\n",
      "Epoch 1000/1000\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/1000\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 0.0604 - val_loss: 0.0477\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(train_gen, \n",
    "                verbose=1, \n",
    "                callbacks=callbacks, \n",
    "                steps_per_epoch = 200, \n",
    "                epochs=1000,\n",
    "                validation_data=(X_tests, y_tests), validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805dc19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_results(history, [\"loss\", \"val_loss\"], \"loss\", \"val_loss\", \"loss vs val_loss\", [\"loss\", \"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37594d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36dbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac732562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad356fe7",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a564794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/ROAR2/lib/python3.6/site-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gen_val = generate_data(X_test, y_test, batch_size)\n",
    "batch, steerings = X_tests, y_tests\n",
    "show_images(batch[0:20], steerings[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6780f85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7257334  -0.03099206]\n",
      " [ 0.7282415  -0.02997875]\n",
      " [ 0.7258089  -0.03151947]\n",
      " [ 0.723645   -0.02982639]\n",
      " [ 0.7173557  -0.0272067 ]\n",
      " [ 0.7224827  -0.02934806]\n",
      " [ 0.73694956 -0.03220716]\n",
      " [ 0.7239997  -0.0299853 ]\n",
      " [ 0.725068   -0.03059665]\n",
      " [ 0.73947847 -0.03285869]\n",
      " [ 0.7292453  -0.03022587]\n",
      " [ 0.72609556 -0.02944672]\n",
      " [ 0.7203013  -0.02878839]\n",
      " [ 0.73282015 -0.03114671]\n",
      " [ 0.71846366 -0.02726747]\n",
      " [ 0.7186389  -0.02778954]\n",
      " [ 0.72474563 -0.03040575]\n",
      " [ 0.728044   -0.02992607]\n",
      " [ 0.7236973  -0.02984569]\n",
      " [ 0.72229487 -0.02917609]]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(m.predict(batch[0:20])).squeeze()\n",
    "predictions = predictions.squeeze()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86968859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.68125933, 0.32448942])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum((predictions - steerings[0:20]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98bd73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"depth_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf882d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fd903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11e90062",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[404736,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-41253a56d2c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"depth_nvidia_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m    206\u001b[0m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0;32m--> 207\u001b[0;31m                                                 compile)\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 184\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    356\u001b[0m             custom_objects=dict(\n\u001b[1;32m    357\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    492\u001b[0m       layer = layer_module.deserialize(layer_config,\n\u001b[1;32m    493\u001b[0m                                        custom_objects=custom_objects)\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     if (not model.inputs and build_input_shape and\n\u001b[1;32m    496\u001b[0m         isinstance(build_input_shape, (tuple, list))):\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2619\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     return super(VarianceScaling, self).__call__(\n\u001b[0;32m--> 410\u001b[0;31m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     return op(\n\u001b[0;32m-> 1082\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ROAR/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[404736,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.models.load_model(\"depth_nvidia_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6154b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610492ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
